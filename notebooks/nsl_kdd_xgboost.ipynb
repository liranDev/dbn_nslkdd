{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc9a6d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "optuna.logging.set_verbosity(optuna.logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e07566e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('..') / 'data'\n",
    "RAW_DATA_PATH = DATA_PATH / 'raw'\n",
    "PROCESSED_DATA_PATH = DATA_PATH / 'processed_v3'\n",
    "\n",
    "MODELS_PATH = Path('..') / 'models'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e99754db",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = (\n",
    "['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
    " 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
    " 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count',\n",
    " 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
    " 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    " 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    " 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'attack', 'level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f5e20b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(RAW_DATA_PATH / 'KDDTrain+.csv')\n",
    "df_test = pd.read_csv(RAW_DATA_PATH / 'KDDTest+.csv')\n",
    "\n",
    "df_train.columns = columns\n",
    "df_test.columns = columns\n",
    "\n",
    "df_train.drop('level', axis=1, inplace=True)\n",
    "df_test.drop('level', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e26c5",
   "metadata": {},
   "source": [
    "# Optimization for Big data\n",
    "\n",
    "based on:  https://www.kaggle.com/bextuychiev/how-to-work-w-million-row-datasets-like-a-pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39d9eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_stats():\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memory_use = py.memory_info()[0] / 2. ** 30\n",
    "    return 'memory GB:' + str(np.round(memory_use, 2))\n",
    "\n",
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                        c_min > np.finfo(np.float16).min\n",
    "                        and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                        c_min > np.finfo(np.float32).min\n",
    "                        and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fea6071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 12.01 Mb (70.2% reduction)\n",
      "Mem. usage decreased to 2.15 Mb (70.2% reduction)\n",
      "memory GB:0.26\n",
      "Memory reduced\n"
     ]
    }
   ],
   "source": [
    "df_train = reduce_memory_usage(df_train, verbose=True)\n",
    "df_test = reduce_memory_usage(df_test, verbose=True)\n",
    "\n",
    "print(cpu_stats())\n",
    "print('Memory reduced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aff769",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "091d7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df_train['protocol_type'] = le.fit_transform(df_train['protocol_type'])\n",
    "df_test['protocol_type'] = le.transform(df_test['protocol_type'])\n",
    "df_train['service'] = le.fit_transform(df_train['service'])\n",
    "df_test['service'] = le.transform(df_test['service'])\n",
    "df_train['flag'] = le.fit_transform(df_train['flag'])\n",
    "df_test['flag'] = le.transform(df_test['flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d8c0ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for i in df_train.attack:\n",
    "    if i == 'normal':\n",
    "        label.append(0)\n",
    "    else:\n",
    "        label.append(1)\n",
    "df_train['label'] = label\n",
    "\n",
    "label_test = []\n",
    "for i in df_test.attack:\n",
    "    if i == 'normal':\n",
    "        label_test.append(0)\n",
    "    else:\n",
    "        label_test.append(1)\n",
    "df_test['label'] = label_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70afe33",
   "metadata": {},
   "source": [
    "### Prepare Test And Train Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "154cea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('attack', axis=1, inplace=True, errors='ignore')\n",
    "df_test.drop('attack', axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "df_train = shuffle(df_train)\n",
    "df_test = shuffle(df_test)\n",
    "\n",
    "\n",
    "y_train = df_train.label\n",
    "\n",
    "X_train = df_train.drop('label', axis=1, inplace=False, errors='ignore')\n",
    "\n",
    "X_test = df_test.drop('label', axis=1, inplace=False, errors='ignore')\n",
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a233975",
   "metadata": {},
   "source": [
    "### Validation Set\n",
    "\n",
    "we use 25% of the test set as validation since we get overfitting if we do cross validaiotn on traning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e795106",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_VAL = 5000 \n",
    "\n",
    "X_test = X_test.iloc[SIZE_VAL:]\n",
    "y_test = y_test.iloc[SIZE_VAL:]\n",
    "X_val  = X_test.iloc[:SIZE_VAL]\n",
    "y_val  = y_test.iloc[:SIZE_VAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d031165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "\n",
    "X_train.to_csv(PROCESSED_DATA_PATH / 'X_train.csv', index=False)\n",
    "X_val.to_csv(PROCESSED_DATA_PATH / 'X_val.csv', index=False)\n",
    "y_train.to_csv(PROCESSED_DATA_PATH / 'y_train.csv', index=False)\n",
    "y_val.to_csv(PROCESSED_DATA_PATH / 'y_val.csv', index=False)\n",
    "X_test.to_csv(PROCESSED_DATA_PATH / 'X_test.csv', index=False)\n",
    "y_test.to_csv(PROCESSED_DATA_PATH / 'y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d170462",
   "metadata": {},
   "source": [
    "# Run XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec5132a",
   "metadata": {},
   "source": [
    "#### trainning and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16ba68fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81      2215\n",
      "           1       0.96      0.67      0.79      2785\n",
      "\n",
      "    accuracy                           0.80      5000\n",
      "   macro avg       0.83      0.82      0.80      5000\n",
      "weighted avg       0.84      0.80      0.80      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgboost_model = XGBClassifier()\n",
    "\n",
    "xgboost_model.fit(X_train, y_train, verbose=False)\n",
    "y_pred_val = xgboost_model.predict(X_val)\n",
    "report = classification_report(y_val, y_pred_val)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ab04e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17543\n",
      "17543\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test))\n",
    "print(len(y_test))\n",
    "print(len(y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c027bd0",
   "metadata": {},
   "source": [
    "#### test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "820ebd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81      2215\n",
      "           1       0.96      0.67      0.79      2785\n",
      "\n",
      "    accuracy                           0.80      5000\n",
      "   macro avg       0.83      0.82      0.80      5000\n",
      "weighted avg       0.84      0.80      0.80      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = xgboost_model.predict(X_test)\n",
    "report_ = classification_report(y_test, y_pred_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c3380b",
   "metadata": {},
   "source": [
    "# Save Model And Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3db8a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model.save_model(MODELS_PATH / f'xgboost_model.json')\n",
    "np.save(PROCESSED_DATA_PATH / 'y_pred_val_xgboost.npy', y_pred_val, allow_pickle=True)\n",
    "np.save(PROCESSED_DATA_PATH / 'y_pred_test_xgboost.npy', y_pred_test, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
